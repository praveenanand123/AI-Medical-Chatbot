import os
import base64
from groq import Groq
from dotenv import load_dotenv
from PIL import Image
import io
import numpy as np
import soundfile as sf
import whisper

load_dotenv()
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
client = Groq(api_key=GROQ_API_KEY)

# Initialize Whisper model for audio transcription
whisper_model = whisper.load_model("base")

def encode_image(image):
    # Convert PIL Image to base64
    buffered = io.BytesIO()
    image.save(buffered, format="JPEG")
    encoded_image = base64.b64encode(buffered.getvalue()).decode("utf-8")
    return encoded_image

def transcribe_audio(audio):
    # Transcribe audio using Whisper
    if isinstance(audio, tuple):
        sr, data = audio
        # Save audio to a temporary file
        temp_audio_path = "temp_audio.wav"
        sf.write(temp_audio_path, data, sr)
    elif isinstance(audio, str):
        temp_audio_path = audio
    else:
        return "Unsupported audio format."

    result = whisper_model.transcribe(temp_audio_path)
    return result["text"]

def analyze_input(text_input=None, image_input=None, audio_input=None, model="meta-llama/llama-4-scout-17b-16e-instruct"):
    messages = []

    # Handle audio input
    if audio_input is not None:
        transcribed_text = transcribe_audio(audio_input)
        messages.append({
            "role": "user",
            "content": [
                {"type": "text", "text": f"{transcribed_text} Please respond in JSON format."}
            ]
        })
    elif text_input:
        messages.append({
            "role": "user",
            "content": [
                {"type": "text", "text": f"{text_input} Please respond in JSON format."}
            ]
        })

    # Handle image input
    if image_input is not None:
        encoded_img = encode_image(image_input)
        messages.append({
            "role": "user",
            "content": [
                {"type": "text", "text": "Please analyze this medical image and respond in JSON format."},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded_img}"}}
            ]
        })

    if not messages:
        return "Please provide a text, image, or audio input."

    response = client.chat.completions.create(
        model=model,
        messages=messages,
        response_format={"type": "json_object"}
    )
    return response.choices[0].message.content

